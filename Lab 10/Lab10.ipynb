{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright **`(c)`** 2023 Giovanni Squillero `<giovanni.squillero@polito.it>`  \n",
    "[`https://github.com/squillero/computational-intelligence`](https://github.com/squillero/computational-intelligence)  \n",
    "Free for personal or classroom use; see [`LICENSE.md`](https://github.com/squillero/computational-intelligence/blob/master/LICENSE.md) for details.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB10\n",
    "\n",
    "Use reinforcement learning to devise a tic-tac-toe player.\n",
    "\n",
    "### Deadlines:\n",
    "\n",
    "* Submission: [Dies Natalis Solis Invicti](https://en.wikipedia.org/wiki/Sol_Invictus)\n",
    "* Reviews: [Befana](https://en.wikipedia.org/wiki/Befana)\n",
    "\n",
    "Notes:\n",
    "\n",
    "* Reviews will be assigned  on Monday, December 4\n",
    "* You need to commit in order to be selected as a reviewer (ie. better to commit an empty work than not to commit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import permutations\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "from termcolor import colored\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "\n",
    "class Player(ABC):\n",
    "    def __init__(self) -> None:\n",
    "        \"\"\"You can change this for your player if you need to handle state/have memory\"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def decide_move(\n",
    "        self, game: \"TicTacToe\", move_symbol: int\n",
    "    ) -> tuple[int, int]:\n",
    "        \"\"\"\n",
    "        game: the TicTacToe game. You can use it to override the current game with yours, but everything is evaluated by the main game\n",
    "        return values: this method shall return a tuple of X,Y positions\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def back_prop(self, reward: int):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "class RLayer(Player):\n",
    "    def __init__(self, path: str = None, epsilon: float = 0.3):\n",
    "        self.game_state = []\n",
    "        self.path = path\n",
    "        self.epsilon = epsilon\n",
    "        self.lr = 0.2\n",
    "        self.gamma_decay = 1.0\n",
    "        if not path:\n",
    "            self.policy = defaultdict(float)\n",
    "        else:\n",
    "            f = open(path, \"r\")\n",
    "            self.policy = json.load(f)\n",
    "\n",
    "    def decide_move(\n",
    "        self, game: \"TicTacToe\", move_symbol: int\n",
    "    ) -> tuple[int, int]:\n",
    "        all_moves = game.possible_moves()\n",
    "        if np.random.random() < self.epsilon:\n",
    "            # exploration phase\n",
    "            index = np.random.randint(len(all_moves))\n",
    "            return all_moves[index]\n",
    "        else:\n",
    "            best_move = None\n",
    "            best_hash = None\n",
    "            best_value = float(\"-inf\")\n",
    "            for move in all_moves:\n",
    "                board_next_move = deepcopy(game)\n",
    "                board_next_move.make_move(move, move_symbol)\n",
    "                hash = board_next_move.hash()\n",
    "                if self.policy[hash] > best_value:\n",
    "                    best_move = move\n",
    "                    best_hash = hash\n",
    "                    best_value = self.policy[hash]\n",
    "            self.game_state.append(best_hash)\n",
    "            return best_move\n",
    "\n",
    "    def back_prop(self, reward: int):\n",
    "        for state in reversed(self.game_state):\n",
    "            # state is an hash of next_board\n",
    "            self.policy[state] += self.lr * (\n",
    "                self.gamma_decay * reward - self.policy[state]\n",
    "            )\n",
    "        self.game_state = []\n",
    "\n",
    "    def save_policy(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TicTacToe:\n",
    "    def __init__(self, board=None):\n",
    "        \"\"\"\n",
    "        Board legend:\n",
    "        cell = 0 -> no move on this cell\n",
    "        cell = 1 -> player 1 made 'x' (1) as move\n",
    "        cell = -1 -> player 2 made 'o' (-1) as move\n",
    "        \"\"\"\n",
    "        train_mode = False\n",
    "        if isinstance(board, np.ndarray):\n",
    "            self.board = board\n",
    "        else:  # all cells initalized at 0\n",
    "            self.board = np.zeros(shape=(3, 3))\n",
    "\n",
    "    def hash(self) -> str:\n",
    "        return str(self.board)\n",
    "\n",
    "    def check_win(self):\n",
    "        \"\"\"Checks if someone won the game.\"\"\"\n",
    "\n",
    "        # Check win by columns\n",
    "        if (abs(self.board.sum(axis=0)) == 3).any():\n",
    "            return True\n",
    "        # Check win by rows\n",
    "        if (abs(self.board.sum(axis=1)) == 3).any():\n",
    "            return True\n",
    "\n",
    "        # Check win by diagonals\n",
    "        sum_diag_princ = 0\n",
    "        sum_diag_back = 0\n",
    "        for i in range(3):\n",
    "            sum_diag_back += self.board[i][i]\n",
    "            sum_diag_princ += self.board[2 - i][i]\n",
    "        if abs(sum_diag_back) == 3 or abs(sum_diag_princ) == 3:\n",
    "            return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    def check_tie(self) -> bool:\n",
    "        if not self.possible_moves():\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def make_move(self, move: tuple[int, int], value: int):\n",
    "        \"\"\"Take a move in format x y and makes it.\"\"\"\n",
    "        x, y = move\n",
    "        # check is a valid move\n",
    "        if not (0 <= x <= 2 and 0 <= y <= 2):\n",
    "            print(\"invalid move\")\n",
    "        elif self.board[x][y] != 0:\n",
    "            print(\"invalid move\")\n",
    "        else:\n",
    "            self.board[x][y] = value\n",
    "\n",
    "    def possible_moves(self):\n",
    "        \"\"\"Return all the possible available moves to make.\"\"\"\n",
    "        moves = []\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                if self.board[i][j] == 0:\n",
    "                    moves.append((i, j))\n",
    "        return moves\n",
    "\n",
    "    def print(self):\n",
    "        l_len = 19\n",
    "        clear_output()\n",
    "        print(f'{colored('Player 1', 'green')} make your move:\\n')\n",
    "        print(\"   \", \"  (0)   (1)   (2)\")\n",
    "        for i in range(3):\n",
    "            print(\"   \", \"-\" * l_len)\n",
    "            print(f\"({i})\", \"| \", end=\"\")\n",
    "            print(\n",
    "                \" | \".join(\n",
    "                    map(\n",
    "                        lambda e: \"   \"\n",
    "                        if e == 0\n",
    "                        else colored(\" X \", \"red\")\n",
    "                        if e == 1\n",
    "                        else colored(\" O \", \"green\"),\n",
    "                        self.board[i].astype(int),\n",
    "                    )\n",
    "                ),\n",
    "                end=\" \",\n",
    "            )\n",
    "            print(\"|\")\n",
    "        print(\"   \", \"-\" * l_len)\n",
    "\n",
    "    def run(\n",
    "        self, player1: Player, player2: Player\n",
    "    ) -> tuple[int, (Player, Player)]:\n",
    "        \"\"\"Returns a int with the winning player index. If tie, the index value will be -1.\"\"\"\n",
    "        board_state = []\n",
    "        someone_won, is_tie = False, False\n",
    "        self.board = np.zeros(shape=(3, 3))\n",
    "        players = [player1, player2]\n",
    "        np.random.shuffle(players)\n",
    "        pl_index = -1\n",
    "        value_to_assign = -1 if isinstance(players[0], RLayer) else 1\n",
    "        if not self.train_mode:\n",
    "            self.print()\n",
    "        while not someone_won and not is_tie:\n",
    "            pl_index += 1\n",
    "            pl_index %= 2\n",
    "            value_to_assign *= -1\n",
    "            move = players[pl_index].decide_move(self, value_to_assign)\n",
    "            self.make_move(move, value_to_assign)\n",
    "            if not self.train_mode:\n",
    "                self.print()\n",
    "            someone_won = self.check_win()\n",
    "            is_tie = self.check_tie()\n",
    "\n",
    "        if is_tie and not someone_won:\n",
    "            pl_index = -1\n",
    "        return (pl_index, players)\n",
    "\n",
    "    def train(self, player1: Player, player2: Player, epochs: int):\n",
    "        self.train_mode = True\n",
    "        bar = tqdm(total=epochs, desc=\"Epoch\")\n",
    "        for _ in range(epochs):\n",
    "            winner_idx, players = self.run(player1, player2)\n",
    "            if winner_idx >= 0:\n",
    "                players[winner_idx].back_prop(1)\n",
    "                players[(winner_idx + 1) % 2].back_prop(0)\n",
    "            else:\n",
    "                players[0].back_prop(0.5)\n",
    "                players[1].back_prop(0.5)\n",
    "            bar.update(1)\n",
    "        self.train_mode = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomPlayer(Player):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "    def decide_move(self, game: \"TicTacToe\", move_symbol: int) -> str:\n",
    "        all_moves = game.possible_moves()\n",
    "        index = np.random.randint(len(all_moves))\n",
    "        return all_moves[index]\n",
    "        # return super().make_move(game)\n",
    "\n",
    "    def back_prop(self, reward: int):\n",
    "        return super().back_prop(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HumanPlayer(Player):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "    def decide_move(\n",
    "        self, game: \"TicTacToe\", move_symbol: int\n",
    "    ) -> tuple[int, int]:\n",
    "        move = input(\"Insert x and y coordinates in format: 'x y' :\")\n",
    "        x, y = move.split(\" \")\n",
    "        return (int(x), int(y))\n",
    "\n",
    "    def back_prop(self, reward: int):\n",
    "        return super().back_prop(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rp = RandomPlayer()\n",
    "rl = RLayer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 100000/100000 [01:11<00:00, 1408.33it/s]\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100000\n",
    "game = TicTacToe()\n",
    "game.train_mode = True\n",
    "game.train(rp, rl, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discovered states: 4489/19683 (22.81%)\n"
     ]
    }
   ],
   "source": [
    "# alanlysis\n",
    "print(f'Discovered states: {len(rl.policy)}/{3**9} ({len(rl.policy)/3**9:.2%})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mPlayer 1\u001b[0m make your move:\n",
      "\n",
      "      (0)   (1)   (2)\n",
      "    -------------------\n",
      "(0) | \u001b[31m X \u001b[0m | \u001b[31m X \u001b[0m | \u001b[31m X \u001b[0m |\n",
      "    -------------------\n",
      "(1) |     |     |     |\n",
      "    -------------------\n",
      "(2) | \u001b[32m O \u001b[0m |     | \u001b[32m O \u001b[0m |\n",
      "    -------------------\n",
      "\n",
      "% of wins of RL: 59.40%\n",
      "% of ties: 11.20%\n",
      "(% of wins other player: 29.40%)\n"
     ]
    }
   ],
   "source": [
    "NUM_GAME = 1000\n",
    "win_rl = 0\n",
    "ties = 0\n",
    "for _ in range(NUM_GAME):\n",
    "    win_idx, players = game.run(rp, rl)\n",
    "    if win_idx != -1 and id(players[win_idx]) == id(rl):\n",
    "        win_rl += 1\n",
    "    elif win_idx == -1:\n",
    "        ties += 1\n",
    "print()\n",
    "print(f\"% of wins of RL: {win_rl/NUM_GAME:.2%}\")\n",
    "print(f\"% of ties: {ties/NUM_GAME:.2%}\")\n",
    "print(f\"(% of wins other player: {1 - ((ties + win_rl)/NUM_GAME):.2%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mPlayer 1\u001b[0m make your move:\n",
      "\n",
      "      (0)   (1)   (2)\n",
      "    -------------------\n",
      "(0) | \u001b[31m X \u001b[0m |     | \u001b[31m X \u001b[0m |\n",
      "    -------------------\n",
      "(1) | \u001b[32m O \u001b[0m | \u001b[32m O \u001b[0m | \u001b[32m O \u001b[0m |\n",
      "    -------------------\n",
      "(2) |     |     |     |\n",
      "    -------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, [<__main__.HumanPlayer at 0x10747b1a0>, <__main__.RLayer at 0x1072a5c70>])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp = HumanPlayer()\n",
    "game.train_mode = False\n",
    "game.run(rl, hp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ci-fLJ3OwGs-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
