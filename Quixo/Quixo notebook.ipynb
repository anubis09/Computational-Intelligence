{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhRzUwn8QNNl"
      },
      "source": [
        "# Game.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qTIBjF2ZQP8U"
      },
      "outputs": [],
      "source": [
        "from abc import ABC, abstractmethod\n",
        "from copy import deepcopy\n",
        "from enum import Enum\n",
        "import numpy as np\n",
        "from termcolor import colored\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "X_zScTRiQTNc"
      },
      "outputs": [],
      "source": [
        "class Move(Enum):\n",
        "    \"\"\"\n",
        "    Selects where you want to place the taken piece. The rest of the pieces are shifted\n",
        "    \"\"\"\n",
        "\n",
        "    TOP = 0\n",
        "    BOTTOM = 1\n",
        "    LEFT = 2\n",
        "    RIGHT = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "31j9kUJoQVAQ"
      },
      "outputs": [],
      "source": [
        "class Player(ABC):\n",
        "    def __init__(self) -> None:\n",
        "        \"\"\"You can change this for your player if you need to handle state/have memory\"\"\"\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def make_move(self, game: \"Game\") -> tuple[tuple[int, int], Move]:\n",
        "        \"\"\"\n",
        "        The game accepts coordinates of the type (X, Y). X goes from left to right, while Y goes from top to bottom, as in 2D graphics.\n",
        "        Thus, the coordinates that this method returns shall be in the (X, Y) format.\n",
        "\n",
        "        game: the Quixo game. You can use it to override the current game with yours, but everything is evaluated by the main game\n",
        "        return values: this method shall return a tuple of X,Y positions and a move among TOP, BOTTOM, LEFT and RIGHT\n",
        "        \"\"\"\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "lR_lx-qjQc5w"
      },
      "outputs": [],
      "source": [
        "class Game(object):\n",
        "    def __init__(self) -> None:\n",
        "        self._board = np.ones((5, 5), dtype=np.uint8) * -1\n",
        "        self.current_player_idx = 1\n",
        "\n",
        "    def get_board(self) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Returns the board\n",
        "        \"\"\"\n",
        "        return deepcopy(self._board)\n",
        "\n",
        "    def get_current_player(self) -> int:\n",
        "        \"\"\"\n",
        "        Returns the current player\n",
        "        \"\"\"\n",
        "        return deepcopy(self.current_player_idx)\n",
        "\n",
        "    def print(self):\n",
        "        \"\"\"Prints the board. -1 are neutral pieces, X are pieces of player 0, O pieces of player 1\"\"\"\n",
        "        BOARD_DIM = 5\n",
        "        l_len = (\n",
        "            BOARD_DIM * 6 + 1\n",
        "        )  # This is just for printing the right number of '-'\n",
        "        os.system(\"cls||clear\")\n",
        "        print(\"   \", \"  (0)   (1)   (2)   (3)   (4)\")\n",
        "        for i in range(BOARD_DIM):\n",
        "            print(\"   \", \"-\" * l_len)\n",
        "            print(f\"({i})\", \"| \", end=\"\")\n",
        "            print(\n",
        "                \" | \".join(\n",
        "                    map(\n",
        "                        lambda e: \"   \"\n",
        "                        if e == -1\n",
        "                        else colored(\" X \", \"red\")\n",
        "                        if e == 0\n",
        "                        else colored(\" O \", \"green\"),\n",
        "                        self._board[i].astype(int),\n",
        "                    )\n",
        "                ),\n",
        "                end=\" \",\n",
        "            )\n",
        "            print(\"|\")\n",
        "        print(\"   \", \"-\" * l_len)\n",
        "\n",
        "    def check_winner(self) -> int:\n",
        "        \"\"\"Check the winner. Returns the player ID of the winner if any, otherwise returns -1\"\"\"\n",
        "        # for each row\n",
        "        player = self.get_current_player()\n",
        "        winner = -1\n",
        "        for x in range(self._board.shape[0]):\n",
        "            # if a player has completed an entire row\n",
        "            if self._board[x, 0] != -1 and all(\n",
        "                self._board[x, :] == self._board[x, 0]\n",
        "            ):\n",
        "                # return winner is this guy\n",
        "                winner = self._board[x, 0]\n",
        "        if winner > -1 and winner != self.get_current_player():\n",
        "            return winner\n",
        "        # for each column\n",
        "        for y in range(self._board.shape[1]):\n",
        "            # if a player has completed an entire column\n",
        "            if self._board[0, y] != -1 and all(\n",
        "                self._board[:, y] == self._board[0, y]\n",
        "            ):\n",
        "                # return the relative id\n",
        "                winner = self._board[0, y]\n",
        "        if winner > -1 and winner != self.get_current_player():\n",
        "            return winner\n",
        "        # if a player has completed the principal diagonal\n",
        "        if self._board[0, 0] != -1 and all(\n",
        "            [self._board[x, x] for x in range(self._board.shape[0])]\n",
        "            == self._board[0, 0]\n",
        "        ):\n",
        "            # return the relative id\n",
        "            winner = self._board[0, 0]\n",
        "        if winner > -1 and winner != self.get_current_player():\n",
        "            return winner\n",
        "        # if a player has completed the secondary diagonal\n",
        "        if self._board[0, -1] != -1 and all(\n",
        "            [self._board[x, -(x + 1)] for x in range(self._board.shape[0])]\n",
        "            == self._board[0, -1]\n",
        "        ):\n",
        "            # return the relative id\n",
        "            winner = self._board[0, -1]\n",
        "        return winner\n",
        "\n",
        "    def play(self, player1: Player, player2: Player) -> int:\n",
        "        \"\"\"Play the game. Returns the winning player\"\"\"\n",
        "        players = [player1, player2]\n",
        "        winner = -1\n",
        "        self.print()\n",
        "        while winner < 0:\n",
        "            self.current_player_idx += 1\n",
        "            self.current_player_idx %= len(players)\n",
        "            ok = False\n",
        "            while not ok:\n",
        "                from_pos, slide = players[self.current_player_idx].make_move(\n",
        "                    self\n",
        "                )\n",
        "                ok = self.__move(from_pos, slide, self.current_player_idx)\n",
        "            self.print()\n",
        "            winner = self.check_winner()\n",
        "        return winner\n",
        "\n",
        "    def __move(\n",
        "        self, from_pos: tuple[int, int], slide: Move, player_id: int\n",
        "    ) -> bool:\n",
        "        \"\"\"Perform a move\"\"\"\n",
        "        if player_id > 2:\n",
        "            return False\n",
        "        # Oh God, Numpy arrays\n",
        "        prev_value = deepcopy(self._board[(from_pos[1], from_pos[0])])\n",
        "        acceptable = self.__take((from_pos[1], from_pos[0]), player_id)\n",
        "        if acceptable:\n",
        "            acceptable = self.__slide((from_pos[1], from_pos[0]), slide)\n",
        "            if not acceptable:\n",
        "                self._board[(from_pos[1], from_pos[0])] = deepcopy(prev_value)\n",
        "        return acceptable\n",
        "\n",
        "    def __take(self, from_pos: tuple[int, int], player_id: int) -> bool:\n",
        "        \"\"\"Take piece\"\"\"\n",
        "        # acceptable only if in border\n",
        "        acceptable: bool = (\n",
        "            # check if it is in the first row\n",
        "            (from_pos[0] == 0 and from_pos[1] < 5)\n",
        "            # check if it is in the last row\n",
        "            or (from_pos[0] == 4 and from_pos[1] < 5)\n",
        "            # check if it is in the first column\n",
        "            or (from_pos[1] == 0 and from_pos[0] < 5)\n",
        "            # check if it is in the last column\n",
        "            or (from_pos[1] == 4 and from_pos[0] < 5)\n",
        "            # and check if the piece can be moved by the current player\n",
        "        ) and (self._board[from_pos] < 0 or self._board[from_pos] == player_id)\n",
        "        if acceptable:\n",
        "            self._board[from_pos] = player_id\n",
        "        return acceptable\n",
        "\n",
        "    def __slide(self, from_pos: tuple[int, int], slide: Move) -> bool:\n",
        "        \"\"\"Slide the other pieces\"\"\"\n",
        "        # define the corners\n",
        "        SIDES = [(0, 0), (0, 4), (4, 0), (4, 4)]\n",
        "        # if the piece position is not in a corner\n",
        "        if from_pos not in SIDES:\n",
        "            # if it is at the TOP, it can be moved down, left or right\n",
        "            acceptable_top: bool = from_pos[0] == 0 and (\n",
        "                slide == Move.BOTTOM\n",
        "                or slide == Move.LEFT\n",
        "                or slide == Move.RIGHT\n",
        "            )\n",
        "            # if it is at the BOTTOM, it can be moved up, left or right\n",
        "            acceptable_bottom: bool = from_pos[0] == 4 and (\n",
        "                slide == Move.TOP or slide == Move.LEFT or slide == Move.RIGHT\n",
        "            )\n",
        "            # if it is on the LEFT, it can be moved up, down or right\n",
        "            acceptable_left: bool = from_pos[1] == 0 and (\n",
        "                slide == Move.BOTTOM or slide == Move.TOP or slide == Move.RIGHT\n",
        "            )\n",
        "            # if it is on the RIGHT, it can be moved up, down or left\n",
        "            acceptable_right: bool = from_pos[1] == 4 and (\n",
        "                slide == Move.BOTTOM or slide == Move.TOP or slide == Move.LEFT\n",
        "            )\n",
        "        # if the piece position is in a corner\n",
        "        else:\n",
        "            # if it is in the upper left corner, it can be moved to the right and down\n",
        "            acceptable_top: bool = from_pos == (0, 0) and (\n",
        "                slide == Move.BOTTOM or slide == Move.RIGHT\n",
        "            )\n",
        "            # if it is in the lower left corner, it can be moved to the right and up\n",
        "            acceptable_left: bool = from_pos == (4, 0) and (\n",
        "                slide == Move.TOP or slide == Move.RIGHT\n",
        "            )\n",
        "            # if it is in the upper right corner, it can be moved to the left and down\n",
        "            acceptable_right: bool = from_pos == (0, 4) and (\n",
        "                slide == Move.BOTTOM or slide == Move.LEFT\n",
        "            )\n",
        "            # if it is in the lower right corner, it can be moved to the left and up\n",
        "            acceptable_bottom: bool = from_pos == (4, 4) and (\n",
        "                slide == Move.TOP or slide == Move.LEFT\n",
        "            )\n",
        "        # check if the move is acceptable\n",
        "        acceptable: bool = (\n",
        "            acceptable_top\n",
        "            or acceptable_bottom\n",
        "            or acceptable_left\n",
        "            or acceptable_right\n",
        "        )\n",
        "        # if it is\n",
        "        if acceptable:\n",
        "            # take the piece\n",
        "            piece = self._board[from_pos]\n",
        "            # if the player wants to slide it to the left\n",
        "            if slide == Move.LEFT:\n",
        "                # for each column starting from the column of the piece and moving to the left\n",
        "                for i in range(from_pos[1], 0, -1):\n",
        "                    # copy the value contained in the same row and the previous column\n",
        "                    self._board[(from_pos[0], i)] = self._board[\n",
        "                        (from_pos[0], i - 1)\n",
        "                    ]\n",
        "                # move the piece to the left\n",
        "                self._board[(from_pos[0], 0)] = piece\n",
        "            # if the player wants to slide it to the right\n",
        "            elif slide == Move.RIGHT:\n",
        "                # for each column starting from the column of the piece and moving to the right\n",
        "                for i in range(from_pos[1], self._board.shape[1] - 1, 1):\n",
        "                    # copy the value contained in the same row and the following column\n",
        "                    self._board[(from_pos[0], i)] = self._board[\n",
        "                        (from_pos[0], i + 1)\n",
        "                    ]\n",
        "                # move the piece to the right\n",
        "                self._board[(from_pos[0], self._board.shape[1] - 1)] = piece\n",
        "            # if the player wants to slide it upward\n",
        "            elif slide == Move.TOP:\n",
        "                # for each row starting from the row of the piece and going upward\n",
        "                for i in range(from_pos[0], 0, -1):\n",
        "                    # copy the value contained in the same column and the previous row\n",
        "                    self._board[(i, from_pos[1])] = self._board[\n",
        "                        (i - 1, from_pos[1])\n",
        "                    ]\n",
        "                # move the piece up\n",
        "                self._board[(0, from_pos[1])] = piece\n",
        "            # if the player wants to slide it downward\n",
        "            elif slide == Move.BOTTOM:\n",
        "                # for each row starting from the row of the piece and going downward\n",
        "                for i in range(from_pos[0], self._board.shape[0] - 1, 1):\n",
        "                    # copy the value contained in the same column and the following row\n",
        "                    self._board[(i, from_pos[1])] = self._board[\n",
        "                        (i + 1, from_pos[1])\n",
        "                    ]\n",
        "                # move the piece down\n",
        "                self._board[(self._board.shape[0] - 1, from_pos[1])] = piece\n",
        "        return acceptable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SR9Il94jQgEC"
      },
      "source": [
        "# Players"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "KPytSA9OQrbX"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "YQWWiiDMQl_O"
      },
      "outputs": [],
      "source": [
        "def random_move() -> tuple[tuple[int, int], Move]:\n",
        "    from_pos = (random.randint(0, 4), random.randint(0, 4))\n",
        "    move = random.choice([Move.TOP, Move.BOTTOM, Move.LEFT, Move.RIGHT])\n",
        "    return from_pos, move\n",
        "\n",
        "\n",
        "class RandomPlayer(Player):\n",
        "    def __init__(self) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "    def make_move(self, game: \"Game\") -> tuple[tuple[int, int], Move]:\n",
        "        return random_move()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "404st0S6QsVu"
      },
      "source": [
        "# Train.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTvhrAldQvBB"
      },
      "source": [
        "IN this section we would like to decide the player neural network architecture and then we would like to train it against a random player and see how it performors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_9kHBZ6-Q4cr"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/r6/vy79dm157pj2x762_z726wr80000gn/T/ipykernel_6967/1918482912.py:1: DeprecationWarning: \n",
            "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
            "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
            "but was not found to be installed on your system.\n",
            "If this would cause problems for you,\n",
            "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
            "        \n",
            "  import pandas as pd\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from collections import deque\n",
        "from numpy import unravel_index\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "class From_Pos_Net(torch.nn.Module):\n",
        "    def __init__(self, gamma=0.9):\n",
        "        super().__init__()\n",
        "        self.optimizer = None\n",
        "        self.gamma = gamma\n",
        "        self.p1 = nn.Linear(\n",
        "            26, 100\n",
        "        )  # 26 because we have 25 integers and 1 int for player id\n",
        "        self.p2 = nn.Linear(100, 100)\n",
        "        self.p3 = nn.Linear(100, 100)\n",
        "        self.p4 = nn.Linear(100, 25)\n",
        "        self.device = \"cpu\"\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.tensor(x, dtype=torch.float32).to(self.device)\n",
        "        x = F.relu(self.p1(x))\n",
        "        x = F.relu(self.p2(x))\n",
        "        x = F.relu(self.p3(x))\n",
        "        from_pos = F.softmax(self.p4(x), dim=-1)\n",
        "\n",
        "        # During the train step he should learn to take the from_pos using the professor convention\n",
        "\n",
        "        return from_pos\n",
        "\n",
        "    def train_net(self, state, next_state, from_pos, target):\n",
        "        if target != 1:\n",
        "            target += self.gamma * torch.max(self.forward(next_state))\n",
        "\n",
        "        output = self.forward(state)\n",
        "        target_f = output.clone()\n",
        "        target_f[np.argmax(from_pos)] = target\n",
        "        target_f.detach()\n",
        "        self.optimizer.zero_grad()\n",
        "        loss = F.mse_loss(output, target_f)\n",
        "        loss.backward()\n",
        "        self.optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "JhJPnB8TLIz5"
      },
      "outputs": [],
      "source": [
        "class Action_Net(torch.nn.Module):\n",
        "    def __init__(self, gamma=0.9):\n",
        "        super().__init__()\n",
        "        self.optimizer = None\n",
        "        self.gamma = gamma\n",
        "        # network for the action\n",
        "        self.a1 = nn.Linear(27, 50)\n",
        "        self.a2 = nn.Linear(50, 50)\n",
        "        self.a3 = nn.Linear(50, 25)\n",
        "        self.a4 = nn.Linear(25, 4)\n",
        "        self.device = \"cpu\"\n",
        "\n",
        "    def forward(self, y):\n",
        "        y = torch.tensor(y, dtype=torch.float32).to(self.device)\n",
        "        y = F.relu(self.a1(y))\n",
        "        y = F.relu(self.a2(y))\n",
        "        y = F.relu(self.a3(y))\n",
        "        act = F.softmax(self.a4(y), dim=-1)\n",
        "\n",
        "        return act\n",
        "\n",
        "    def train_net(self, state, next_state, action, target):\n",
        "        if target != 1:\n",
        "            target += self.gamma * torch.max(self.forward(next_state))\n",
        "\n",
        "        output = self.forward(state)\n",
        "        target_f = output.clone()\n",
        "        target_f[np.argmax(action)] = target\n",
        "        target_f.detach()\n",
        "        self.optimizer.zero_grad()\n",
        "        loss = F.mse_loss(output, target_f)\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "        return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "dXI27s1FRuDg"
      },
      "outputs": [],
      "source": [
        "class DeepQTrain(Player):\n",
        "    def __init__(self, params):\n",
        "        self._epsilon = 0.3\n",
        "        self.train_mode = True\n",
        "        self.file_name = \"si andiamo in exploration\"\n",
        "        self.learning_rate = params[\"learning_rate\"]\n",
        "        self.weight_path = params[\"weight_path\"]\n",
        "        self.memory = []\n",
        "        self.from_pos_net = From_Pos_Net()\n",
        "        self.from_pos_net.optimizer = optim.Adam(\n",
        "            self.from_pos_net.parameters(),\n",
        "            weight_decay=0,\n",
        "            lr=self.learning_rate,\n",
        "        )\n",
        "        self.action_net = Action_Net()\n",
        "        self.action_net.optimizer = optim.Adam(\n",
        "            self.action_net.parameters(), weight_decay=0, lr=self.learning_rate\n",
        "        )\n",
        "\n",
        "        DEVICE = \"cpu\"\n",
        "        self.from_pos_net.to(DEVICE)\n",
        "        self.action_net.to(DEVICE)\n",
        "\n",
        "    def set_epsilon(self, eps: int) -> None:\n",
        "        self._epsilon = eps\n",
        "\n",
        "    def get_epsilon(self) -> int:\n",
        "        return self._epsilon\n",
        "\n",
        "    def make_move(self, game: \"Game\") -> tuple[tuple[int, int], Move]:\n",
        "        input = game.get_board()\n",
        "        from_pos_net_input = np.append(input, game.get_current_player())\n",
        "\n",
        "        if self.train_mode and np.random.random() < self._epsilon:\n",
        "            possible_moves = game.get_possible_moves()\n",
        "            index = np.random.choice(len(possible_moves))\n",
        "            move = possible_moves[index]\n",
        "        else:\n",
        "            from_pos = self.from_pos_net(from_pos_net_input)\n",
        "            from_pos = from_pos.reshape(5, 5)  # we reshape it in matrix form.\n",
        "            from_pos = unravel_index(\n",
        "                from_pos.cpu().argmax(), from_pos.shape\n",
        "            )  # we take the position of the matrix we are interested into.\n",
        "            # this will be part of the additional input to the action net.\n",
        "            act_net_input = np.append(input, from_pos)\n",
        "            act = self.action_net.forward(act_net_input)\n",
        "            act = act.cpu().argmax().numpy()\n",
        "\n",
        "            move = (from_pos, Move(act))\n",
        "\n",
        "        # vorrei la memoria fatta da (board_state+player, (move, act))\n",
        "        self.memory.append((from_pos_net_input, move))\n",
        "\n",
        "        return move\n",
        "\n",
        "    # Now we need to design the train function.\n",
        "    # It needs to assign the reward, and the idea should be like more important to the last move, less important\n",
        "    # to the first move.\n",
        "    # The for each move, we have the reward and we use the function from below.\n",
        "    # To assigna the reward value we will use the Q_value update? Yes probably.\n",
        "    def back_prop(self, reward: int):\n",
        "        for idx in range(len(self.memory) - 1):\n",
        "            curr_state, move = self.memory[idx]\n",
        "            curr_pos, curr_move = move\n",
        "            next_state, n_move = self.memory[idx + 1]\n",
        "            next_pos, _ = n_move\n",
        "            r = 0 if idx < len(self.memory) - 2 else reward\n",
        "            self.from_pos_net.train_net(curr_state, next_state, curr_pos, r)\n",
        "            self.action_net.train_net(\n",
        "                np.append(curr_state[:-1], curr_pos),\n",
        "                np.append(next_state[:-1], next_pos),\n",
        "                curr_move,\n",
        "                r,\n",
        "            )\n",
        "\n",
        "        self.memory = []\n",
        "\n",
        "    def save_policy(self):\n",
        "        from_pos_weights = self.from_pos_net.state_dict()\n",
        "        act_weights = self.action_net.state_dict()\n",
        "        torch.save(from_pos_weights, \"from_pos_net.h5\")\n",
        "        torch.save(act_weights, \"action_net.h5\")\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLHlE5QRlHOt"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### New Game subclass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "_Rwuezm3GVzc"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "K7uFCZmLSw7C"
      },
      "outputs": [],
      "source": [
        "class GameTrainer(Game):\n",
        "    def __init__(self) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "    def print(self) -> None:\n",
        "        # os.system(\"cls||clear\")\n",
        "        pass\n",
        "\n",
        "    def __acceptable_slides(self, from_position: tuple[int, int]):\n",
        "        \"\"\"When taking a piece from {from_position} returns the possible moves (slides)\"\"\"\n",
        "        acceptable_slides = [Move.BOTTOM, Move.TOP, Move.LEFT, Move.RIGHT]\n",
        "        axis_0 = from_position[0]  # axis_0 = 0 means uppermost row\n",
        "        axis_1 = from_position[1]  # axis_1 = 0 means leftmost column\n",
        "\n",
        "        if axis_0 == 0:  # can't move upwards if in the top row...\n",
        "            acceptable_slides.remove(Move.TOP)\n",
        "        elif axis_0 == 4:\n",
        "            acceptable_slides.remove(Move.BOTTOM)\n",
        "\n",
        "        if axis_1 == 0:\n",
        "            acceptable_slides.remove(Move.LEFT)\n",
        "        elif axis_1 == 4:\n",
        "            acceptable_slides.remove(Move.RIGHT)\n",
        "        return acceptable_slides\n",
        "\n",
        "    def get_possible_moves(self):\n",
        "        # __acceptable_slides -> prende from_pos e ritorna le slides possibili.\n",
        "        # for solo sugli element di contorno. e prendiamo le posizion. poi abbiamo acceptable_slides che ci dice le slide possivbili.\n",
        "        moves = []\n",
        "        for row in [0, 4]:\n",
        "            for col in range(5):\n",
        "                if (\n",
        "                    self._board[row, col] == self.current_player_idx\n",
        "                    or self._board[row, col] == -1\n",
        "                ):\n",
        "                    slides = self.__acceptable_slides((row, col))\n",
        "                    for slide in slides:\n",
        "                        moves.append(((col, row), slide))\n",
        "                if (\n",
        "                    self._board[col, row] == self.current_player_idx\n",
        "                    or self._board[col, row] == -1\n",
        "                ):\n",
        "                    slides = self.__acceptable_slides((col, row))\n",
        "                    for slide in slides:\n",
        "                        moves.append(((row, col), slide))\n",
        "        return moves\n",
        "\n",
        "    def play(self, player1: Player, player2: Player) -> int:\n",
        "        self._board = np.full((5, 5), -1, dtype=np.int8)\n",
        "        self.current_player_idx = -1\n",
        "        players = [player1, player2]\n",
        "        winner = -3\n",
        "        n_move = 0\n",
        "        while winner < 0 and n_move < 150:\n",
        "            self.current_player_idx += 1\n",
        "            self.current_player_idx %= len(players)\n",
        "            ok = False\n",
        "            in_loop = 0\n",
        "            while not ok:\n",
        "                in_loop += 1\n",
        "                from_pos, slide = players[self.current_player_idx].make_move(\n",
        "                    self\n",
        "                )\n",
        "                ok = self._Game__move(from_pos, slide, self.current_player_idx)\n",
        "                if in_loop > 200:\n",
        "                    pass\n",
        "            n_move += 1\n",
        "            winner = self.check_winner()\n",
        "        return winner\n",
        "\n",
        "    # look at the problem of the starting position.\n",
        "    # The idea could be to leave the play as it is, then we can make our players play as first then as second.\n",
        "    # we can also make array players shuffle. -> i'll go with this solution\n",
        "    def train(self, trainee: Player, trainer: Player, epochs: int) -> None:\n",
        "        if not trainee.file_name:\n",
        "            print(\"starting full exploration mode\")\n",
        "            trainee.set_epsilon(1)\n",
        "        # if isinstance(trainer, RLayer) and not trainer.file_name:\n",
        "        # trainer.set_epsilon(1)\n",
        "        players = [trainee, trainer]\n",
        "        winning_reward = 1\n",
        "        losing_reward = -3\n",
        "        first_draw_reward = 0.1\n",
        "        second_draw_reward = 0.5\n",
        "        bar = tqdm(total=epochs, desc=\"Epoch\")\n",
        "        for ep in range(epochs):\n",
        "            if ep % (epochs // 30) == 0:\n",
        "                old_eps = trainee.get_epsilon()\n",
        "                new_eps = old_eps - 0.1 if old_eps > 0.3 else old_eps\n",
        "                # eps decrease at the same rate for both.\n",
        "                trainee.set_epsilon(new_eps)\n",
        "                # if isinstance(trainer, RLayer):\n",
        "                # trainer.set_epsilon(new_eps)\n",
        "            np.random.shuffle(players)\n",
        "            winner_idx = self.play(players[0], players[1])\n",
        "            loser_idx = (winner_idx + 1) % 2\n",
        "            if winner_idx != -1:\n",
        "                if isinstance(players[winner_idx], DeepQTrain):\n",
        "                    players[winner_idx].back_prop(winning_reward)\n",
        "                if isinstance(players[loser_idx], DeepQTrain):\n",
        "                    players[loser_idx].back_prop(losing_reward)\n",
        "            else:\n",
        "                if isinstance(players[0], DeepQTrain):\n",
        "                    # if first start draws, not very good.\n",
        "                    players[0].back_prop(first_draw_reward)\n",
        "                if isinstance(players[1], DeepQTrain):\n",
        "                    # if second starting draws, good for him\n",
        "                    players[1].back_prop(second_draw_reward)\n",
        "            bar.update(1)\n",
        "        if isinstance(trainee, DeepQTrain):\n",
        "            trainee.save_policy()\n",
        "        # if isinstance(trainer, RLayer):\n",
        "        #     trainer.save_policy()\n",
        "        return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdASFutklXtq"
      },
      "source": [
        "# Prova"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "iaPcVQFYlZMb"
      },
      "outputs": [],
      "source": [
        "game = GameTrainer()\n",
        "trainee = DeepQTrain({\"learning_rate\": 0.001, \"weight_path\": \"ciao\"})\n",
        "trainer = RandomPlayer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8UX0sZFlfVi",
        "outputId": "f9b1851b-b953-401a-93b5-cae0035fee77"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 100%|██████████| 100000/100000 [2:00:39<00:00, 13.81it/s] \n"
          ]
        }
      ],
      "source": [
        "game.train(trainee, trainer, 100_000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "hSj_t22BHqLe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "starting evaluation\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Game #: 100%|█████████▉| 1997/2000 [00:15<00:00, 133.66it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Wins as first: 0.45%\n",
            "Wins as second: 0.40%\n",
            "total percentage: 0.42%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Game #: 100%|██████████| 2000/2000 [00:26<00:00, 133.66it/s]"
          ]
        }
      ],
      "source": [
        "trainee.is_training = False\n",
        "n_game = 1000\n",
        "\n",
        "print(\"starting evaluation\")\n",
        "bar = tqdm(total=n_game * 2, desc=\"Game #\")\n",
        "\n",
        "wins_as_first = 0\n",
        "for _ in range(n_game):\n",
        "    winner = game.play(trainee, RandomPlayer())\n",
        "    if winner == 0:\n",
        "        wins_as_first += 1\n",
        "    bar.update(1)\n",
        "\n",
        "\n",
        "wins_as_second = 0\n",
        "for _ in range(n_game):\n",
        "    winner = game.play(RandomPlayer(), trainee)\n",
        "    if winner == 1:\n",
        "        wins_as_second += 1\n",
        "    bar.update(1)\n",
        "\n",
        "print(\"\")\n",
        "print(f\"Wins as first: {wins_as_first/n_game:.2f}%\")\n",
        "print(f\"Wins as second: {wins_as_second/n_game:.2f}%\")\n",
        "\n",
        "print(f\"total percentage: {(wins_as_first + wins_as_second)/(n_game*2):.2f}%\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "HhRzUwn8QNNl",
        "SR9Il94jQgEC"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
